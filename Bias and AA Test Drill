1. You're testing advertising emails for a bathing suit company and you test one version of the email in February and the other in May.
- Contexual Bias: May is closer to summer and Febraury is closer to spring break. Each time period has its own bias and can skew results.

2. You open a clinic to treat anxiety and find that the people who visit show a higher rate of anxiety than the general population.
- Selection/Sampling Bias: You are sampling more of one type of person. Sample is of individuals who come to clinic and 
  are mainly going to be individuals who suffer from axiety because it is a clinic for anxiety.
- Observer Bias: Observer is clearly looking for indiviuals with anxiety. By making the clinic treatable for 'anxiety' they have an 
  expected outcome.

3. You launch a new ad billboard based campaign and see an increase in website visits in the first week.
- The first thought I have is that the initial design of the test is not proper. There is no experimental and control groups. 
  You cannot assume that all website visits came from individuals who saw the billboard. There are also variables that can be overlooked. 
  Was the website on sale that week? It also might be of interest to measure longer than a week. 
  Does the performance continue to increase 2 weeks after billboard? How about after the billboard is taken down? 
  Is the site still on sale? If customer engagement is steady it could have nothing to do with the billboard and more to do with the sale. 
  May not have any bias but the experiment is flawed.

4. You launch a loyalty program but see no change in visits in the first week.
- While it is not stated in the scenario above, the loyalty program conditions may be contexually biased. 
  How many subscribers or customers actually viewed the loyalty program or got information about it? 
  Additionally, 1 week is not long enough for the experiment to be conducted. 
  Also, maybe focus on a different key metric, maybe sign ups for program, rather than visits. 
